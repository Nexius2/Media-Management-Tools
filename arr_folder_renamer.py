# -*- coding: utf-8 -*-

"""
#########################################################
# Media Management Tools (MMT) - Arr folder renamer
# Auteur       : Nexius2
# Version      : 2.1.xx
# Description  : Script permettant de modifier le path pour correspondre aux besoins de Plex via Sonarr et Radarr
#                en fonction des crit√®res d√©finis dans `config.json`.
# Licence      : MIT
#########################################################
"""

import json
import logging
import sys
from logging.handlers import RotatingFileHandler
import requests
import time
import re
import unidecode
from datetime import datetime, timedelta
from fuzzywuzzy import fuzz
from pathlib import Path



# Charger la configuration
CONFIG_FILE = "config.json"
RADARR_CACHE_FILE = "cache_radarr_paths.json"
SONARR_CACHE_FILE = "cache_sonarr_paths.json"
VERSION = "2.1.57"





try:
    with open(CONFIG_FILE, "r", encoding="utf-8") as f:
        config = json.load(f)
    logging.info("‚úÖ Configuration charg√©e avec succ√®s.")
except FileNotFoundError:
    logging.error(f"‚ùå Erreur : fichier de configuration '{CONFIG_FILE}' introuvable.")
    exit(1)
except json.JSONDecodeError as e:
    logging.error(f"‚ùå Erreur de parsing JSON dans '{CONFIG_FILE}': {e}")
    exit(1)

# üìå R√©cup√©ration des param√®tres de config
SONARR_URL = config["services"]["sonarr"]["url"]
SONARR_API_KEY = config["services"]["sonarr"]["api_key"]
RADARR_URL = config["services"]["radarr"]["url"]
RADARR_API_KEY = config["services"]["radarr"]["api_key"]
PLEX_URL = config["services"]["plex"]["url"]
PLEX_API_KEY = config["services"]["plex"]["api_key"]
LOG_FILE = config["arr_folder_renamer"]["log_file"]
LOG_LEVEL = logging.getLevelName(config["arr_folder_renamer"]["log_level"].upper())
DRY_RUN = config["arr_folder_renamer"]["dry_run"]
WORK_LIMIT = config["arr_folder_renamer"]["work_limit"]
RUN_SONARR = config["arr_folder_renamer"]["run_sonarr"]
RUN_RADARR = config["arr_folder_renamer"]["run_radarr"]


# üî• Correction du logging : R√©initialisation compl√®te
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

logging.basicConfig(
    level=LOG_LEVEL,  # ‚úÖ DEBUG pour voir tous les logs
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),  # ‚úÖ Force l'affichage dans la console
        RotatingFileHandler(LOG_FILE, maxBytes=5 * 1024 * 1024, backupCount=5, encoding="utf-8"),
        logging.FileHandler(LOG_FILE, encoding="utf-8")  # ‚úÖ Ajout d'un log fichier
    ]
)
logging.debug("üöÄ Syst√®me de logs initialis√©.")

def load_radarr_cache():
    try:
        with open(RADARR_CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_radarr_cache(cache):
    with open(RADARR_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, indent=2, ensure_ascii=False)

def load_sonarr_cache():
    try:
        with open(SONARR_CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_sonarr_cache(cache):
    with open(SONARR_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, indent=2, ensure_ascii=False)


# üìå R√©cup√©ration du format de dossier depuis Radarr/Sonarr
def get_movie_folder_format(api_url, api_key, service_name):
    try:
        response = requests.get(f"{api_url}/api/v3/config/naming", headers={"X-Api-Key": api_key}, timeout=60)
        response.raise_for_status()
        data = response.json()
        folder_format = data.get("movieFolderFormat" if service_name == "Radarr" else "seriesFolderFormat")
        
        if folder_format:
            logging.info(f"‚úÖ {service_name} - Folder Format: {folder_format}")
            #print(f"üìÇ {service_name} - movieFolderFormat: {folder_format}")
        else:
            logging.warning(f"‚ö†Ô∏è {service_name} - Aucun format r√©cup√©r√©, v√©rifier la configuration.")
        
        return folder_format
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration du format de dossier {service_name}: {e}")
        return None




# üìå Extraction des Folder Name Tokens avec accolades
def get_folder_name_tokens(folder_format, service_name):
    if not folder_format:
        logging.warning(f"‚ö†Ô∏è {service_name} - Aucun format trouv√© pour extraire les tokens.")
        return []

    tokens = re.findall(r"\{[^{}]+\}", folder_format)  # Capture les tokens avec les accolades
    return tokens



# R√©cup√©rer les valeurs des tokens depuis Radarr/Sonarr
def get_movie_details(api_url, api_key, movie_id):
    """
    R√©cup√®re les d√©tails d'un film depuis Radarr via son ID.
    """
    try:
        response = requests.get(f"{api_url}/api/v3/movie/{movie_id}", headers={"X-Api-Key": api_key}, timeout=60)
        response.raise_for_status()
        movie_data = response.json()
        logging.info(f"‚úÖ D√©tails r√©cup√©r√©s pour le film: {movie_data.get('title', 'Titre inconnu')} (ID: {movie_id})")
        return movie_data
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des d√©tails du film {movie_id} : {e}")
        return None

# R√©cup√©rer tous les films et extraire les tokens
def get_all_movies(api_url, api_key, max_retries=5, wait_time=10):
    """
    R√©cup√®re la liste de tous les films dans Radarr et extrait leurs informations.
    """
    logging.info(f"üì° R√©cup√©ration des films ayant un fichier depuis {api_url}...")    
#    try:
#        response = requests.get(f"{api_url}/api/v3/movie", headers={"X-Api-Key": api_key}, timeout=5)
#        response.raise_for_status()
#        movies = response.json()
#        logging.info(f"üìä {len(movies)} films r√©cup√©r√©s avec succ√®s.")


        # Filtrer les films qui ont un fichier
#        movies_with_files = [movie for movie in movies if movie.get("hasFile", False)]
        
#        logging.info(f"üìä {len(movies_with_files)} films avec fichier r√©cup√©r√©s avec succ√®s.")
        #logging.info(f"üìú Contenu brut de la r√©ponse de Radarr: {movies}")
#        return movies_with_files
#    except requests.exceptions.RequestException as e:
#        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des films : {e}")
#        return []
    attempt = 0
    while attempt < max_retries:
        try:
            if attempt > 1:
                logging.info(f"üì° Tentative {attempt + 1}/{max_retries} - R√©cup√©ration des films depuis Radarr...")

            response = requests.get(f"{api_url}/api/v3/movie", headers={"X-Api-Key": api_key}, timeout=60)
            response.raise_for_status()
            movies = response.json()
            logging.info(f"üìä {len(movies)} films r√©cup√©r√©s avec succ√®s.")
            
            # ‚úÖ Retourne imm√©diatement si succ√®s
            return [movie for movie in movies if movie.get("hasFile", False)]

        except requests.exceptions.RequestException as e:
            logging.warning(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des films : {e} - R√©essai dans {wait_time} secondes...")
            time.sleep(wait_time)
            wait_time *= 10  # Augmente le temps d‚Äôattente progressivement
            attempt += 1

    # ‚ùå Apr√®s plusieurs tentatives, on abandonne
    logging.error(f"‚ùå √âchec apr√®s {max_retries} tentatives. Impossible de r√©cup√©rer les films depuis Radarr.")
    sys.exit(0)  # ‚úÖ Quitte proprement le script
    return []




# üìå Extraction dynamique des valeurs des tokens
def extract_token_values(movie_data, tokens):
    """
    Extrait les valeurs des tokens √† partir des d√©tails du film r√©cup√©r√©.
    """
    logging.debug(f"üîç Extraction des valeurs des tokens pour le film : {movie_data.get('title', 'Titre inconnu')}")
    logging.debug(f"üìú Tokens attendus : {tokens}")

    # Mapping entre les tokens Radarr et les champs r√©els de l'API
    token_map = {
        "Release Year": "year",
        "Movie CleanTitle": "title",  # On va le nettoyer nous-m√™mes
        "TmdbId": "tmdbId",
        "ImdbId": "imdbId"
    }

    token_values = {}

    for token in tokens:
        clean_token = token.strip("{}")  # Supprime les accolades

        if clean_token == "Movie CleanTitle":
            value = generate_clean_title(movie_data.get("title", "Unknown Title"))  # Nettoyage
        elif clean_token in token_map:
            api_field = token_map[clean_token]
            value = movie_data.get(api_field)
            if not value:
                value = f"Unknown-{clean_token}"

        else:
            value = f"Unknown-{clean_token}"  # Par d√©faut, si le champ n'existe pas

        token_values[token] = value  # Garde le format {Token}

    logging.debug(f"‚úÖ Valeurs extraites : {token_values}")
    return token_values

def extract_series_token_values(series_data, tokens):
    """
    Extrait les valeurs des tokens pour une s√©rie (Sonarr) en √©vitant le doublon d'ann√©e.
    """
    logging.debug(f"üìú Donn√©es brutes de la s√©rie ID {series_data.get('id')} : {json.dumps(series_data, indent=4)}")

    # R√©cup√©rer les infos de la s√©rie
    title = series_data.get("title", "Unknown")
    year = str(series_data.get("year", series_data.get("firstAired", "0000")[:4]))

    # V√©rifier si l'ann√©e est d√©j√† pr√©sente dans le titre (ex: "Yellowstone (2018)")
    if f"({year})" in title:
        title_year = title  # On garde tel quel
    else:
        title_year = f"{title} ({year})"  # On ajoute l'ann√©e seulement si elle n'est pas d√©j√† l√†

    # Mapping des tokens
    token_map = {
        "Series TitleYear": title_year,
        "ImdbId": series_data.get("imdbId", "Unknown-ImdbId"),
        "TvdbId": series_data.get("tvdbId", "Unknown-TvdbId")
    }

    token_values = {f"{{{key}}}": value for key, value in token_map.items()}

    logging.info(f"‚úÖ Valeurs extraites pour Sonarr : {token_values}")
    return token_values



# üìå G√©n√©ration du new_path
# üìå G√©n√©ration du new_path avec un '/' devant
def generate_new_path(root_folder, folder_format, token_values):
    new_path = folder_format
    for token, value in token_values.items():
        if "Unknown" in str(value):
            new_path = new_path.replace(token, "")
        else:
            new_path = new_path.replace(token, str(value))

        
    # ‚úÖ Correction : √©viter un double `root_folder`
    if new_path.startswith(root_folder):
        final_path = new_path.replace("//", "/")
    else:
        final_path = f"{root_folder}/{new_path}".replace("//", "/")
    
    # ‚úÖ Ajout d'un `/` √† la fin pour s'assurer qu'il s'agit bien d'un dossier


    #return final_path.rstrip("/") + "/"
    final_path = final_path.rstrip("/") + "/"
    logging.debug(f"üìÇ Root Folder utilis√©: {root_folder}")
    logging.debug(f"üìÇ Nouveau chemin g√©n√©r√© (final_path): {final_path}")
    return final_path

def generate_series_path(root_folder, folder_format, token_values):
    """
    G√©n√®re le chemin de destination pour une s√©rie dans Sonarr.
    """
    new_path = folder_format

    # üîπ Remplace les tokens sp√©cifiques √† Sonarr
    for token, value in token_values.items():
        if "Unknown" in str(value):
            new_path = new_path.replace(token, "")
        else:
            new_path = new_path.replace(token, str(value))


    # üîπ Construit le chemin final (sans os)
    final_path = root_folder.rstrip("/") + "/" + new_path.rstrip("/") + "/"

    logging.info(f"üì∫ Chemin g√©n√©r√© pour Sonarr : {final_path}")
    return final_path

# üìå Mise √† jour du chemin dans Radarr
def update_movie_path(api_url, api_key, movie_id, new_path, root_folder, root_folder_path, movies_to_process):
    """
    Met √† jour le chemin d'un film dans Radarr avec tous les champs requis.
    """
    
    
    logging.debug(f"üìÇ D√©but de la mise √† jour du chemin pour le film ID {movie_id}")
    logging.debug(f"üìÇ Root Folder Path utilis√©: {root_folder_path}")
    root_folders = get_root_folders(api_url, api_key)

    # V√©rifie si le chemin actuel est d√©j√† correct
    current_path = get_movie_details(api_url, api_key, movie_id).get("path", "").rstrip("/")
    if current_path == new_path.rstrip("/"):
        logging.info(f"‚úÖ Le film {movie_id} est d√©j√† dans le bon dossier ({new_path}), aucune modification n√©cessaire.")
        return False
    else:
        # Sinon, on v√©rifie que le rootFolder est bien pr√©sent
        if not any(folder["path"].rstrip("/") == root_folder_path.rstrip("/") for folder in root_folders):
            logging.error(f"‚ùå Erreur : le dossier rootFolderPath '{root_folder_path}' n'existe pas dans Radarr.")
            logging.debug(f"‚úÖ Le film {movie_id} dans le dossier ({new_path})")
            logging.debug(f"üìÇ üìú Liste des rootFolders disponibles dans Radarr: {[folder['path'] for folder in root_folders]}")
            return False


    max_attempts = 3  # ‚úÖ Limite le nombre de tentatives pour √©viter une boucle infinie
    attempt = 0


    # üìå √âtape 1 : R√©cup√©rer les d√©tails complets du film depuis Radarr
    movie_details = get_movie_details(api_url, api_key, movie_id)
    if not movie_details:
        logging.error(f"‚ùå Impossible de r√©cup√©rer les d√©tails du film {movie_id}.")
        return False
        
        
    # üìå V√©rifier si le chemin est d√©j√† correct
    current_path = movie_details.get("path", "").rstrip("/")
    if current_path == new_path.rstrip("/"):
        logging.info(f"‚úÖ Le film {movie_id} est d√©j√† dans le bon dossier ({new_path}), aucune modification n√©cessaire.")
        return False  # üöÄ On √©vite un appel inutile √† l'API

    logging.info(f"üìÇ Chemin actuel r√©cup√©r√© de Radarr: {current_path}")
    logging.info(f"üìÇ Nouveau chemin souhait√© : {new_path}")

    # ‚úÖ V√©rifier que `qualityProfileId` est bien pr√©sent et correct
    quality_profile_id = movie_details.get("qualityProfileId", 0)
    if quality_profile_id <= 0:
        logging.error(f"‚ùå Film {movie_id} - `qualityProfileId` est invalide : {quality_profile_id}")
        return true

    # ‚úÖ R√©cup√©rer `rootFolderPath`
#    root_folder_path = movie_details.get("rootFolderPath", "")
#    if not root_folder_path:
#        logging.error(f"‚ùå Film {movie_id} - `rootFolderPath` introuvable.")
#        return False

    sort_title = movie_details.get("sortTitle", "")
    year = movie_details.get("year", "")
    metadataProfileId = movie_details.get("metadataProfileId")

    #logging.info(f"üìÇ Chemin actuel r√©cup√©r√© de Radarr: {movie_details.get('path', 'Inconnu')}")



    # üìå √âtape 2 : Construire la requ√™te de mise √† jour avec tous les champs n√©cessaires
    payload = {
        "id": movie_details["id"],
        "title": movie_details["title"],
        "sortTitle": sort_title,
        "year": year,
        "path": new_path,
        "monitored": movie_details["monitored"],
        "qualityProfileId": quality_profile_id,
        "metadataProfileId": movie_details.get("metadataProfileId"),
        "tmdbId": movie_details["tmdbId"],
        "imdbId": movie_details.get("imdbId", "")
       # "moveFiles": True  # ‚úÖ Obligatoire pour d√©placer les fichiers
    }

    if DRY_RUN:
        logging.info(f"[DRY_RUN] Simulation de modification du chemin pour le film ID {movie_id} -> {new_path}")
        logging.info(f"[DRY_RUN] Simulation de modification du chemin pour le film ID {movie_id} -> {new_path}")
        logging.info(f"[DRY_RUN] Requ√™te API qui aurait √©t√© envoy√©e √† Radarr :")
        #logging.info(f"URL: {api_url}/api/v3/movie/{movie_id}")
        #logging.info(f"Headers: {{'X-Api-Key': '{api_key}'}}")
        #logging.info(f"Payload: {json.dumps(payload, indent=4)}")  # ‚úÖ Formate le JSON pour qu'il soit lisible
        return True

    # üìå √âtape 3 : Envoyer la requ√™te PUT
    try:
        response = requests.put(
            f"{api_url}/api/v3/movie/{movie_id}?moveFiles=true",
            headers={"X-Api-Key": api_key},
            json=payload,
            timeout=60
        )
        response.raise_for_status()
        logging.info(f"‚úÖ Film ID {movie_id} - Chemin mis √† jour: {new_path}")
        logging.debug("‚è≥ Pause pour laisser Radarr enregistrer le changement...")
        time.sleep(10)  # Pause pour √©viter que Radarr traite une base vide
        
        # ‚úÖ Forcer Radarr √† rescanner le film apr√®s la mise √† jour du chemin
        #force_rescan(api_url, api_key, movie_id)
        #time.sleep(1)  # Pause pour √©viter que Radarr ignore le d√©placement
        
        while attempt < max_attempts:
            logging.info(f"üîÅ Tentative {attempt + 1}/{max_attempts} : V√©rification des fichiers apr√®s changement de chemin...")
            
            if verify_movie_files(api_url, api_key, movie_id):
                logging.info(f"‚úÖ Radarr d√©tecte les fichiers apr√®s modification du chemin pour le film {movie_id}.")
                #start_time = time.time()
                #response = requests.get(f"{api_url}/api/v3/movie", headers={"X-Api-Key": api_key}, timeout=300)
                #logging.info(f"üìä Radarr a mis {time.time() - start_time:.2f} secondes pour r√©pondre.")


                # ‚úÖ Maintenant que tous les d√©placements sont termin√©s, on peut rescanner
                #force_rescan(api_url, api_key, movie_id)
                movie_titles = [movie["title"] for movie in movies_to_process]  # Liste des titres des films trait√©s
                #movie_titles = [movie["title"] for movie in processed_movies]  # ‚úÖ Seulement les films trait√©s
                #movie_titles = [movie_details["title"]]  # ‚úÖ R√©cup√®re correctement le titre du film


                logging.debug("Liste des films pass√©.")
                
                # ‚úÖ Attendre que MoveMovieService ait d√©plac√© tous les films avant de rescanner
                if wait_for_movie_moves(api_url, api_key, movie_titles):
                    logging.info("‚ôªÔ∏è Tous les films d√©plac√©s, lancement du rescan.")
                    force_rescan(api_url, api_key, movie_id)
                    #for movie_id in [movie_id]:  # Assure que movie_id est bien une liste it√©rable
                    for movie_id in [processed_movies]:  # Assure que movie_id est bien une liste it√©rable
                        logging.info("‚ö†Ô∏è rescan du film {movie_id}.")

                        force_rescan(api_url, api_key, movie_id)
                else:
                    logging.debug("‚ö†Ô∏è Certains films n'ont pas √©t√© d√©plac√©s ou plus de films a controler, rescan annul√©.")


                #force_movie_move(api_url, api_key, movie_id)
                
                return True
            
            logging.warning(f"‚ö†Ô∏è Radarr ne d√©tecte pas encore les fichiers apr√®s modification du chemin pour le film {movie_id}. Rescan en cours...")
            #force_rescan(api_url, api_key, movie_id)
            #time.sleep(1)  # ‚úÖ Pause pour √©viter un rescan trop rapide
            attempt += 1

        logging.error(f"‚ùå √âchec apr√®s {max_attempts} tentatives : Radarr ne trouve toujours pas les fichiers.")
        return False
    
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la mise √† jour du chemin pour le film {movie_id} : {e}")
        return False


def generate_clean_title(title):
    """
    G√©n√®re le 'Movie CleanTitle' en nettoyant le titre du film.
    """
    if not title:
        return "Unknown-Title"

    clean_title = title.lower()  # Convertit en minuscules pour standardiser
    clean_title = re.sub(r"[^a-zA-Z0-9 ]", "", clean_title)  # Supprime les caract√®res sp√©ciaux
    clean_title = re.sub(r"\s+", " ", clean_title).strip()  # Remplace les espaces multiples par un seul
    return clean_title.title()  # Remet en majuscule la premi√®re lettre de chaque mot


def force_movie_move(api_url, api_key, movie_id):
    """
    Force Radarr √† renommer et d√©placer les fichiers du film apr√®s un changement de chemin.
    """
    max_attempts = 3  # ‚úÖ Limite le nombre de tentatives pour √©viter une boucle infinie
    attempt = 0

    # ‚úÖ R√©cup√©rer le movieFileId AVANT d'envoyer la commande
    moviefile_id = get_movie_file_id(api_url, api_key, movie_id)
    
    if not moviefile_id:
        logging.error(f"‚ùå Aucun fichier trouv√© pour le film {movie_id}. Impossible de renommer.")
        return False

    while attempt < max_attempts:
        logging.info(f"üîÅ Tentative {attempt + 1}/{max_attempts} : D√©clenchement du d√©placement de fichiers pour le film {movie_id}...")

        try:
            response = requests.post(
                f"{api_url}/api/v3/command",
                headers={"X-Api-Key": api_key},
                json={"name": "RenameMovieFiles", "movieId": movie_id, "files": [moviefile_id]},  # ‚úÖ Ajout du movieFileId
                timeout=60
            )
            response.raise_for_status()
            logging.info(f"‚úÖ D√©placement des fichiers d√©clench√© avec succ√®s pour le film {movie_id}.")
            return True  # ‚úÖ Succ√®s -> on arr√™te ici

        except requests.exceptions.RequestException as e:
            logging.error(f"‚ùå Erreur lors du d√©clenchement du d√©placement des fichiers pour le film {movie_id} : {e}")

        attempt += 1
        time.sleep(1)  # ‚úÖ Pause pour √©viter un spam de requ√™tes

    logging.error(f"‚ùå √âchec : Impossible de d√©clencher le d√©placement des fichiers apr√®s {max_attempts} tentatives.")
    return False  # üö® On arr√™te les tentatives




def verify_movie_files(api_url, api_key, movie_id):
    """
    V√©rifie si Radarr d√©tecte les fichiers associ√©s au film apr√®s un changement de chemin.
    """
    try:
        for attempt in range(5):  # Ajout de 5 tentatives au lieu d'une seule
            response = requests.get(
                f"{api_url}/api/v3/moviefile?movieId={movie_id}",
                headers={"X-Api-Key": api_key},
                timeout=60
            )
            response.raise_for_status()
            files = response.json()

            if files:
                logging.info(f"‚úÖ {len(files)} fichier(s) trouv√©(s) pour le film {movie_id} apr√®s d√©placement.")
                return True

            logging.warning(f"‚ö†Ô∏è Aucun fichier d√©tect√© dans Radarr apr√®s la mise √† jour du chemin pour le film {movie_id}. Tentative {attempt+1}/5")
            time.sleep(10)  # Pause plus longue avant une nouvelle tentative

        logging.error(f"‚ùå √âchec : Radarr ne trouve toujours pas les fichiers apr√®s 5 tentatives.")
        return False

    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la v√©rification des fichiers dans Radarr pour le film {movie_id}: {e}")
        return False



def get_root_folders(api_url, api_key):
    """
    R√©cup√®re la liste des dossiers racines configur√©s dans Radarr.
    """
    try:
        response = requests.get(
            f"{api_url}/api/v3/rootFolder",
            headers={"X-Api-Key": api_key},
            timeout=30
        )
        response.raise_for_status()
        root_folders = response.json()

        logging.debug(f"üìÇ Dossiers racines trouv√©s dans Radarr: {[folder['path'] for folder in root_folders]}")
        #logging.error(f" Films concern√©: {[movie['title'] for movie in movies_to_process]}")
        
        return root_folders

    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des dossiers racines de Radarr: {e}")
        return []




def force_rescan(api_url, api_key, movie_id):
    """
    Force Radarr √† rescanner un film apr√®s mise √† jour du chemin.
    """
    logging.info(f"üîÑ Rescan du film {movie_id} en cours...")
    try:
        response = requests.post(
            f"{api_url}/api/v3/command",
            headers={"X-Api-Key": api_key},
            json={"name": "RescanMovie", "movieId": movie_id},
            timeout=60
        )
        response.raise_for_status()
        logging.info(f"‚úÖ Rescan lanc√© pour le film {movie_id}.")
        return True

    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors du rescan du film {movie_id} : {e}")
        return False


def get_movie_file_id(api_url, api_key, movie_id):
    """
    R√©cup√®re l'ID du fichier associ√© au film dans Radarr.
    """
    response = requests.get(
        f"{api_url}/api/v3/moviefile?movieId={movie_id}",
        headers={"X-Api-Key": api_key},
        timeout=60
    )
    
    if response.status_code != 200:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration du fichier du film {movie_id}.")
        return None

    movie_files = response.json()
    
    if movie_files:
        moviefile_id = movie_files[0]["id"]
        logging.info(f"‚úÖ MovieFile ID trouv√© : {moviefile_id} pour le film {movie_id}")
        return moviefile_id
    else:
        logging.warning(f"‚ö†Ô∏è Aucun fichier trouv√© pour le film {movie_id}. Impossible de renommer.")
        return None


def get_queue(api_url, api_key):
    """
    R√©cup√®re la file d'attente (queue) des t√¢ches en cours de traitement dans Sonarr ou Radarr.
    """
    try:
        response = requests.get(f"{api_url}/api/v3/queue", headers={"X-Api-Key": api_key}, timeout=60)
        response.raise_for_status()

        # ‚úÖ V√©rifier si la r√©ponse est bien du JSON
        try:
            queue_data = response.json()
        except json.JSONDecodeError:
            logging.error(f"‚ùå Erreur : r√©ponse non JSON re√ßue de {api_url}/api/v3/queue")
            return []

        # ‚úÖ Extraire uniquement la liste des t√¢ches (champ `records`)
        if isinstance(queue_data, dict) and "records" in queue_data:
            return queue_data["records"]
        
        logging.error(f"‚ùå Erreur : r√©ponse inattendue re√ßue de {api_url}/api/v3/queue : {queue_data}")
        return []

    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration de la file d'attente ({api_url}) : {e}")
        return []


    

def wait_for_completion(arr_url, arr_api_key, max_retries=20, wait_time=60):
    """
    Attend la fin des traitements en cours dans Sonarr ou Radarr avant de poursuivre.
    """

    logging.info(f"üîÑ V√©rification de la file d'attente sur {arr_url}...")

    last_non_empty_attempt = 0  # Stocke la derni√®re tentative o√π la queue n'√©tait pas vide

    for attempt in range(max_retries):
        arr_queue = get_queue(arr_url, arr_api_key)

        # ‚úÖ V√©rifier que `arr_queue` est une liste
        if not isinstance(arr_queue, list):
            logging.error(f"‚ùå Erreur : r√©ponse inattendue de {arr_url}/api/v3/queue : {arr_queue}")
            return False

        # Filtrer les t√¢ches qui ne sont pas termin√©es
        active_tasks = [task for task in arr_queue if isinstance(task, dict) and task.get("status") not in ["completed", "warning"]]

        logging.info(f"üìú Queue active ({len(active_tasks)} t√¢ches en cours): {[task.get('status') for task in active_tasks]}")

        if not active_tasks:
            # V√©rification suppl√©mentaire pour √©viter les faux positifs
            if attempt - last_non_empty_attempt >= 3:  # 3 it√©rations vides avant confirmation
                logging.info("‚úÖ Toutes les t√¢ches sont termin√©es. Fin de l'attente.")
                return True
            else:
                logging.info("üîÑ La queue est vide, mais on attend encore quelques it√©rations pour confirmation...")
        else:
            last_non_empty_attempt = attempt  # R√©initialisation car il reste des t√¢ches actives

        logging.info(f"‚è≥ Attente {wait_time} secondes avant nouvelle v√©rification... (Tentative {attempt+1}/{max_retries})")
        time.sleep(wait_time)

    logging.error("‚ùå Les t√¢ches en attente dans Sonarr/Radarr n'ont pas √©t√© termin√©es √† temps.")
    return False

# üìå R√©cup√©ration des d√©tails d'une s√©rie depuis Sonarr
def get_series_details(api_url, api_key, series_id):
    """
    R√©cup√®re les d√©tails d'une s√©rie depuis Sonarr via son ID.
    """
    try:
        response = requests.get(f"{api_url}/api/v3/series/{series_id}", headers={"X-Api-Key": api_key}, timeout=60)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des d√©tails de la s√©rie {series_id} : {e}")
        return None


# üìå R√©cup√©ration de toutes les s√©ries depuis Sonarr
def get_all_series(api_url, api_key, max_retries=3, initial_timeout=60):
    """
    R√©cup√®re la liste de toutes les s√©ries dans Sonarr avec un timeout adaptatif.
    """
    timeout = initial_timeout
    for attempt in range(max_retries):
        try:
            logging.info(f"üì° Tentative {attempt + 1}/{max_retries} - Timeout: {timeout}s")
            response = requests.get(f"{api_url}/api/v3/series?includeEpisodeFileCount=true",
                                    headers={"X-Api-Key": api_key}, timeout=timeout)
            response.raise_for_status()
            series = response.json()
            logging.info(f"üìä {len(series)} s√©ries r√©cup√©r√©es avec succ√®s.")
            return [s for s in series if s.get("statistics", {}).get("episodeFileCount", 0) > 0]
        except requests.exceptions.Timeout:
            logging.warning(f"‚ö†Ô∏è Timeout apr√®s {timeout}s. Augmentation du timeout et nouvelle tentative...")
            timeout += 10  # On augmente le timeout √† chaque √©chec
        except requests.exceptions.RequestException as e:
            logging.error(f"‚ùå Erreur Sonarr: {e}")
            return []

    logging.error(f"‚ùå √âchec apr√®s {max_retries} tentatives. Impossible de r√©cup√©rer les s√©ries.")
    return []


# üìå Mise √† jour du chemin dans Sonarr
def update_series_path(api_url, api_key, series_id, new_path, root_folder_path):
    """
    Met √† jour le chemin d'une s√©rie dans Sonarr.
    """
    try:
        series_details = get_series_details(api_url, api_key, series_id)
        if not series_details:
            return False

        current_path = series_details.get("path", "").rstrip("/")
        if current_path == new_path.rstrip("/"):
            logging.info(f"‚úÖ La s√©rie {series_id} est d√©j√† dans le bon dossier ({new_path}), aucune modification n√©cessaire.")
            return False

        # Mise √† jour du chemin
        series_details["path"] = new_path
        series_details["rootFolderPath"] = root_folder_path

        # Nettoyage des champs inutiles ou √† risque
        for key in ["seriesType", "cleanTitle", "sortTitle", "tags", "episodeFileCount", "episodeCount", "status"]:
            series_details.pop(key, None)

        if DRY_RUN:
            logging.info(f"[DRY_RUN] Simulation de modification du chemin pour la s√©rie ID {series_id} -> {new_path}")
            return True

        logging.debug(f"üîß Payload envoy√© √† Sonarr pour mise √† jour:\n{json.dumps(series_details, indent=2)}")

        response = requests.put(
            f"{api_url}/api/v3/series/{series_id}",
            headers={"X-Api-Key": api_key},
            json=series_details,
            timeout=60
        )
        response.raise_for_status()
        logging.info(f"‚úÖ S√©rie ID {series_id} - Chemin mis √† jour: {new_path}")

        force_series_rescan(api_url, api_key, series_id)
        return True

    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 409:
            logging.error(f"‚ùå Erreur 409 : Conflit lors du d√©placement de la s√©rie ID {series_id}")
            logging.error(f"üîé Chemin conflictuel : {new_path}")
            if Path(new_path).exists():
                logging.warning(f"‚ö†Ô∏è Le dossier {new_path} existe sur le disque. V√©rifie s‚Äôil est li√© √† une autre s√©rie dans Sonarr.")
            else:
                logging.warning("‚ö†Ô∏è Le dossier n‚Äôexiste pas sur le disque. Il peut s‚Äôagir d‚Äôun conflit en base Sonarr.")
        else:
            logging.error(f"‚ùå Erreur HTTP Sonarr : {e}")
        return False

    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors de la mise √† jour du chemin pour la s√©rie {series_id} : {e}")
        return False




# üìå Forcer un rescan de la s√©rie
def force_series_rescan(api_url, api_key, series_id):
    """
    Force Sonarr √† rescanner une s√©rie apr√®s mise √† jour du chemin.
    """
    logging.info(f"üîÑ Rescan de la s√©rie {series_id} en cours...")
    try:
        response = requests.post(
            f"{api_url}/api/v3/command",
            headers={"X-Api-Key": api_key},
            json={"name": "RescanSeries", "seriesId": series_id},
            timeout=60
        )
        response.raise_for_status()
        logging.info(f"‚úÖ Rescan lanc√© pour la s√©rie {series_id}.")
        return True
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå Erreur lors du rescan de la s√©rie {series_id} : {e}")
        return False


# üìå Traitement des s√©ries dans Sonarr
def process_sonarr(sonarr_cache):
    logging.info("üöÄ D√©but du traitement Sonarr...")
    sonarr_cache = load_sonarr_cache()
    logging.info(f"üìä {len(sonarr_cache)} s√©ries dans le cache.")

    folder_format = get_movie_folder_format(SONARR_URL, SONARR_API_KEY, "Sonarr")
    logging.info(f"üé¨ Series Folder Format de Sonarr: {folder_format}")
    tokens = get_folder_name_tokens(folder_format, "Sonarr")

    series_list = get_all_series(SONARR_URL, SONARR_API_KEY)
    logging.info(f"üìä {len(series_list)} s√©ries trouv√©es dans Sonarr.")
    logging.info("üìä Recherche de s√©ries √† traiter.")

    processed_series = []
    count = 0

    for series in series_list:
        series_id = str(series["id"])
        if WORK_LIMIT > 0 and count >= WORK_LIMIT:
            logging.info("üîπ WORK_LIMIT atteint pour Sonarr, arr√™t du traitement.")
            break

        if series_id in sonarr_cache:
            logging.debug(f"‚è≠Ô∏è S√©rie ID {series_id} d√©j√† dans le cache, on saute.")
            continue

        token_values = extract_series_token_values(series, tokens)
        root_folder_path = series.get("rootFolderPath", "/media/Series").rstrip("/")
        root_folders = get_root_folders_sonarr(SONARR_URL, SONARR_API_KEY)
        if not any(root_folder_path == folder.get("path", "").rstrip("/") for folder in root_folders):
            logging.warning(f"‚ùå Dossier racine non valide pour la s√©rie {series_id} : {root_folder_path}")
            continue

        new_path = generate_series_path(root_folder_path, folder_format, token_values)
        current_path = series.get("path", "").rstrip("/")

        if current_path == new_path.rstrip("/"):
            logging.info(f"‚úÖ La s√©rie {series['title']} est d√©j√† dans le bon dossier ({current_path}), aucune modification n√©cessaire.")
            sonarr_cache[series_id] = new_path.rstrip("/")
            logging.debug(f"‚úÖ S√©rie {series_id} ajout√©e au cache : {new_path}")
            continue

        logging.info(f"üìÇ Chemin actuel r√©cup√©r√© de Sonarr: {current_path}")
        logging.info(f"üìÇ Nouveau chemin souhait√© : {new_path}")

        result = update_series_path(
            SONARR_URL,
            SONARR_API_KEY,
            series["id"],
            new_path,
            root_folder_path
        )

        sonarr_cache[series_id] = new_path.rstrip("/")

        if result and series not in processed_series:
            processed_series.append(series)
            count += 1
            logging.info(f"{count} s√©ries trait√©es")

    save_sonarr_cache(sonarr_cache)
    if processed_series:
        wait_for_series_moves(processed_series)

    logging.info(f"üíæ Cache Sonarr sauvegard√© avec {len(sonarr_cache)} s√©ries.")
    logging.info("‚úÖ Fin du traitement Sonarr.")

def get_root_folders_sonarr(api_url, api_key):
    try:
        response = requests.get(
            f"{api_url}/api/v3/rootfolder",
            headers={"X-Api-Key": api_key},
            timeout=10
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des dossiers racine Sonarr : {e}")
        return []



def normalize_title(title):
    """ Nettoie et normalise un titre pour √©viter les diff√©rences de format. """
    if not title:
        return ""
    title = unidecode.unidecode(title)  # Supprime les accents
    title = re.sub(r"[^a-zA-Z0-9]", "", title.lower().strip())  # Supprime tout sauf lettres et chiffres
    return title

def is_title_match(expected_title, moved_title, threshold=85):
    """ V√©rifie si deux titres sont similaires en utilisant Fuzzy Matching. """
    score = fuzz.ratio(expected_title, moved_title)
    return score >= threshold






def wait_for_movie_moves(api_url, api_key, processed_movies, max_retries=5, wait_time=10):
    """
    V√©rifie si les films trait√©s ont bien √©t√© d√©plac√©s en analysant les logs de Radarr.
    Ne prend en compte que les logs des derni√®res 12 heures et limite la requ√™te.
    """
    retries = 0
    moved_movies = set()
    max_pages = 3  # ‚úÖ Limite stricte des pages de logs analys√©es
    log_time_threshold = datetime.utcnow() - timedelta(hours=12)  # ‚úÖ Seulement les 12 derni√®res heures

    logging.debug("üü¢ D√©but de wait_for_movie_moves()")

    # ‚úÖ V√©rification et formatage de `processed_movies`
    if not isinstance(processed_movies, list) or not processed_movies:
        logging.error("‚ùå `processed_movies` est vide ou invalide !")
        return False

    expected_titles = {normalize_title(movie["title"]) for movie in processed_movies if isinstance(movie, dict) and "title" in movie}
    
    logging.debug(f"üìú Films attendus apres controle({len(expected_titles)}) : {sorted(expected_titles)}")
    if not expected_titles:
        logging.debug("‚ùå plus de titre valide r√©cup√©r√© dans `processed_movies`.")
        return False

    

    while retries < max_retries:
        try:
            logs = []
            page = 1
            logging.info(f"üì° V√©rification des logs Radarr - Tentative {retries + 1}/{max_retries}")

            while page <= max_pages:
                response = requests.get(
                    f"{api_url}/api/v3/log?page={page}&pageSize=50&sortKey=time&sortDirection=descending",
                    headers={"X-Api-Key": api_key}, timeout=30
                )

                if response.status_code != 200:
                    logging.error(f"‚ùå Erreur API ({response.status_code}) en r√©cup√©rant les logs.")
                    return False

                response.raise_for_status()
                new_logs = response.json().get("records", [])

                if not new_logs:
                    logging.info(f"üìú Fin de la r√©cup√©ration des logs (Page {page} vide).")
                    break  # ‚úÖ Arr√™t si plus de logs

                logs.extend(new_logs)
                logging.info(f"üìú Page {page} r√©cup√©r√©e avec {len(new_logs)} entr√©es.")

                # ‚úÖ Filtrage des logs contenant "moved successfully to" et r√©cents (< 12h)
                for log in new_logs:
                    log_time = datetime.strptime(log["time"], "%Y-%m-%dT%H:%M:%SZ")
                    if log_time < log_time_threshold:
                        continue  # ‚ùå Trop ancien, on ignore

                    message = log.get("message", "").lower()
                    if "moved successfully to" in message:
                        moved_title = normalize_title(message.split("moved successfully to")[0].strip())
                        if moved_title in expected_titles:
                            logging.info(f"üéØ Film d√©plac√© d√©tect√© : {message}")
                            moved_movies.add(moved_title)

                if moved_movies >= expected_titles:
                    logging.info(f"‚úÖ Tous les films d√©plac√©s ({len(moved_movies)}/{len(expected_titles)}).")
                    return True  # ‚úÖ Succ√®s, on sort

                page += 1

            remaining_movies = expected_titles - moved_movies
            logging.warning(f"‚è≥ Films encore en d√©placement ({len(remaining_movies)}) : {sorted(remaining_movies)}")
            
            if retries >= 3 and not moved_movies:
                logging.error("‚ùå Aucun film d√©plac√© apr√®s plusieurs tentatives, sortie forc√©e.")
                return False

            time.sleep(wait_time)
            wait_time += 5  # ‚úÖ D√©lai progressif pour √©viter le spam API
            retries += 1

        except requests.exceptions.RequestException as e:
            logging.error(f"‚ùå Erreur API Radarr : {e}")
            return False

    logging.warning("‚ö†Ô∏è Certains films d√©plac√©s n'ont pas √©t√© d√©tect√©s apr√®s plusieurs tentatives.")
    return False


def wait_for_series_moves(series_list):
    for series in series_list:
        series_id = series["id"]
        title = series["title"]

        for attempt in range(1, 4):
            logging.info(f"üîÅ Tentative {attempt}/3 : V√©rification des fichiers pour la s√©rie {series_id} apr√®s changement de chemin...")

            try:
                response = requests.get(
                    f"{SONARR_URL}/api/v3/episodefile?seriesId={series_id}",
                    headers={"X-Api-Key": SONARR_API_KEY},
                    timeout=10
                )
                response.raise_for_status()
                files = response.json()

                if files:
                    logging.info(f"‚úÖ {len(files)} fichier(s) trouv√©(s) pour la s√©rie {series_id} apr√®s d√©placement.")
                    break
                else:
                    logging.warning(f"‚ö†Ô∏è Aucun fichier trouv√© pour la s√©rie {series_id}.")
            except Exception as e:
                logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des fichiers pour la s√©rie {series_id} : {e}")

            time.sleep(2)







def check_radarr_move_logs():
    """
    V√©rifie les logs de Radarr pour s'assurer que les d√©placements de films sont termin√©s.
    """
    url = f"{RADARR_URL}/api/v3/log?page=1&pageSize=50"
    headers = {"X-Api-Key": RADARR_API_KEY}

    max_attempts = 10
    for attempt in range(max_attempts):
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            logs = response.json().get("records", [])

            # Recherche des logs de d√©placement de film
            move_logs = [log for log in logs if log["logger"] == "MoveMovieService"]

            if not move_logs:  # Aucun d√©placement d√©tect√©
                logging.info("‚úÖ Aucun d√©placement en cours dans les logs de Radarr. On peut continuer.")
                return True
            else:
                logging.info(f"‚è≥ {len(move_logs)} d√©placements d√©tect√©s dans Radarr, attente de 30s...")

        else:
            logging.error(f"‚ùå Erreur lors de la r√©cup√©ration des logs Radarr. Code: {response.status_code}")

        time.sleep(30)  # Attente avant la prochaine v√©rification

    logging.warning("‚ö†Ô∏è Temps d'attente √©coul√©, passage √† l'√©tape suivante malgr√© tout.")
    return False

# üìå Traitement des films dans Radarr
def process_radarr(radarr_cache):
    logging.debug("üì° √âtape 1 : R√©cup√©ration du Movie Folder Format de Radarr...")
    folder_format = get_movie_folder_format(RADARR_URL, RADARR_API_KEY, "Radarr")

    if folder_format:
        logging.info(f"üé¨ Movie Folder Format de Radarr: {folder_format}")

        # Extraction des tokens
        logging.debug("üì° √âtape 3 : Extraction des tokens...")
        tokens = get_folder_name_tokens(folder_format, "Radarr")

        if tokens:
            logging.info(f"üì° Tokens extraits: {tokens}")

            logging.debug("üì° √âtape 5 : R√©cup√©ration de tous les films depuis Radarr...")
            movies = get_all_movies(RADARR_URL, RADARR_API_KEY)

            if not movies:
                logging.warning("‚ö†Ô∏è √âtape 6 : Aucun film r√©cup√©r√© depuis Radarr ! V√©rifie l'API.")
            else:
                logging.info(f"üìä {len(movies)} films trouv√©s dans Radarr.")
                logging.info (f"üìä Recherche de films a traiter.")

            processed_movies = []  # ‚úÖ Liste des films r√©ellement d√©plac√©s dans cette session
            count = 0

            for movie in movies:
                if WORK_LIMIT > 0 and count >= WORK_LIMIT:
                    logging.debug("üîπ WORK_LIMIT atteint, arr√™t du traitement.")
                    
                    break
                
                movie_id = str(movie["id"])
                # üîç Skip si d√©j√† dans le cache
                if movie_id in radarr_cache:
                    logging.debug(f"‚è≠Ô∏è Film ID {movie_id} d√©j√† trait√©, on saute.")
                    continue
                
                logging.debug(f"üé¨ √âtape 8 : D√©but du traitement du film : {movie.get('title', 'Titre inconnu')}")

                token_values = extract_token_values(movie, tokens)
                new_path = generate_new_path(movie["rootFolderPath"], folder_format, token_values)
                
                cached_path = radarr_cache.get(str(movie_id))
                if cached_path and cached_path == new_path.rstrip("/"):
                    logging.debug(f"‚è≠Ô∏è Film {movie_id} d√©j√† dans le bon dossier (via cache), on saute.")
                    continue


                # ‚úÖ V√©rifier si le chemin est d√©j√† correct
                current_path = movie.get("path", "").rstrip("/")
                if current_path == new_path.rstrip("/"):
                    logging.debug(f"‚úÖ Le film {movie['title']} est d√©j√† dans le bon dossier, aucun changement n√©cessaire.")
                    radarr_cache[movie_id] = new_path.rstrip("/")  # ‚ûï On ajoute au cache
                    continue  # Passe au film suivant

                logging.debug(f"üìÇ √âtape 12 : new_path g√©n√©r√©: {new_path}")

                # ‚úÖ Met √† jour uniquement si n√©cessaire
                result = update_movie_path(RADARR_URL, RADARR_API_KEY, movie_id, new_path, movie["rootFolderPath"], movie["rootFolderPath"], movies)

                # dans la boucle principale
                if result:
                    radarr_cache[movie_id] = new_path.rstrip("/")
                    processed_movies.append(movie)
                    count += 1
                    logging.info(f"{count} films trait√©s")
                else:
                    logging.info(f"üîÑ Aucun changement requis pour le film ID {movie_id}, on passe au suivant.")
                    radarr_cache[movie_id] = new_path.rstrip("/")


            logging.info(f"‚úÖ Fin du traitement. {count} films modifi√©s.")
            logging.debug(f"‚úÖ liste processed_movies: {processed_movies} ")

    save_radarr_cache(radarr_cache)
    logging.info(f"üíæ Cache sauvegard√© avec {len(radarr_cache)} films.")


# üìå Rafra√Æchissement de Plex
def plex_refresh(plex_url, plex_api_key, main_logger):
    """ Rafra√Æchit les biblioth√®ques Plex """
    headers = {"X-Plex-Token": plex_api_key}
    response = requests.get(f"{plex_url}/library/sections/all/refresh", headers=headers)
    if response.status_code == 200:
        main_logger.info("‚úÖ Actualisation de la biblioth√®que Plex r√©ussie.")
    else:
        main_logger.error("‚ùå √âchec de l'actualisation de la biblioth√®que Plex.")

# üìå Ex√©cution principale
def main():
    logging.info("üöÄ D√©marrage du script...")
    logging.info(f"üõ†Ô∏è  Version de l'outil : {VERSION}")
    
    radarr_cache = load_radarr_cache()
    logging.info(f"üìä {len(radarr_cache)} films dans le cache.")
    sonarr_cache = load_sonarr_cache()
    logging.info(f"üìä {len(sonarr_cache)} series dans le cache.")

    if RUN_RADARR:
        process_radarr(radarr_cache)

    if RUN_SONARR:
        process_sonarr(sonarr_cache)

    # ‚úÖ Rafra√Æchissement Plex apr√®s traitement
    if not DRY_RUN:
        #movie_titles = [movie["title"] for movie in processed_movies]
        #if RUN_RADARR and wait_for_movie_moves(RADARR_URL, RADARR_API_KEY, processed_movies):
        if RUN_RADARR:# and wait_for_movie_moves(RADARR_URL, RADARR_API_KEY, movie_titles):
            logging.debug("‚ôªÔ∏è Radarr refresh done...")
        if RUN_SONARR:# and wait_for_completion(SONARR_URL, SONARR_API_KEY, max_retries=10, wait_time=30):
            logging.info("‚ôªÔ∏è Sonarr refresh done...")
        logging.info("‚ôªÔ∏è Rafra√Æchissement de Plex...")
        plex_refresh(PLEX_URL, PLEX_API_KEY, logging)
        logging.info("‚úÖ Plex a √©t√© actualis√© avec succ√®s.")
    else:
        logging.error("‚ùå Impossible de rafra√Æchir Plex car Sonarr/Radarr n'ont pas termin√© √† temps.")

    logging.info("‚úÖ Fin du script.")

if __name__ == "__main__":
    main()



